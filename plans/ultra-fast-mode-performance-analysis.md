# Ultra Fast Mode Performance Analysis

## Executive Summary

This document analyzes the ultra fast mode implementation in the SAJ H2 Modbus Home Assistant integration, which polls data at 1-second intervals. The analysis identifies several performance bottlenecks and provides specific optimization strategies to reduce resource usage while maintaining data freshness.

---

## 1. Current Implementation Overview

### 1.1 Ultra Fast Mode Configuration

| Parameter | Value | Location |
|-----------|-------|----------|
| Polling Interval | 1 second | `hub.py:44` |
| Config Key | `ultra_fast_enabled` | `hub.py:33` |
| Data Source | `read_additional_modbus_data_1_part_2` | `hub.py:336` |
| Registers Read | 25 registers (address 16533) | `modbus_readers.py:292-296` |
| Sensors Monitored | 18 power-related sensors | `hub.py:48-54` |

### 1.2 Ultra Fast Update Flow

```mermaid
sequenceDiagram
    participant Timer
    participant Hub
    participant Connection
    participant Modbus
    participant MQTT

    Timer->>Hub: Every 1 second
    Hub->>Connection: get_client()
    Connection->>Connection: Acquire _connection_lock
    Connection->>Modbus: Check connected
    Connection-->>Hub: Return client
    Hub->>Modbus: read_additional_modbus_data_1_part_2()
    Modbus->>Modbus: Acquire _read_lock
    Modbus->>Modbus: Read 25 registers
    Modbus->>Modbus: Decode 18 values
    Modbus-->>Hub: Return data dict
    Hub->>Hub: Filter to FAST_POLL_SENSORS
    Hub->>Hub: Update inverter_data
    Hub->>MQTT: publish_data(fast_data)
    Note over Hub: No HA entity updates (to avoid DB spam)
```

### 1.3 Key Components

#### Hub.py - Ultra Fast Loop (Lines 318-352)

```python
async def _async_update_fast(self, now=None, ultra: bool = False) -> None:
    """Perform fast update of sensor data."""
    if not self.fast_enabled and not ultra:
        return
    
    try:
        client = await self.connection.get_client()  # Lock acquisition
        result = await modbus_readers.read_additional_modbus_data_1_part_2(
            client, self._read_lock  # Another lock acquisition
        )
        
        if result:
            fast_data = {k: v for k, v in result.items() if k in self._fast_poll_sensor_keys}
            if fast_data:
                self.inverter_data.update(result)  # Full dict update
                await self.mqtt.publish_data(fast_data)  # MQTT publish

                # Only the 10s loop should push to HA entities
                if not ultra:
                    for listener in self._fast_listeners:
                        listener()
    except ReconnectionNeededError:
        await self.connection.reconnect()
    except Exception as e:
        _LOGGER.warning("Fast update failed: %s", e)
```

#### Modbus Readers - Data Read (Lines 451-452)

```python
async def read_additional_modbus_data_1_part_2(client: ModbusTcpClient, lock: Lock) -> DataDict:
    return await _read_configured_data(client, lock, "additional_data_1_part_2")
```

Configuration:
```python
"additional_data_1_part_2": {
    "address": 16533,
    "count": 25,
    "decode_map": ADDITIONAL_DATA_1_PART_2_MAP,
    "data_key": "additional_data_1_part_2",
    "default_factor": 1,
}
```

#### Services.py - Connection Management (Lines 55-59)

```python
async def get_client(self) -> ModbusTcpClient:
    """Returns a connected client, establishing connection if needed."""
    async with self._connection_lock:  # Lock acquisition every 1s
        self._client = await connect_if_needed(self._client, self._host, self._port)
        return self._client
```

---

## 2. Identified Performance Bottlenecks

### 2.1 Lock Contention (HIGH IMPACT)

**Problem**: Single `_read_lock` shared across all polling loops

| Loop | Interval | Lock Usage | Contention Risk |
|------|----------|------------|-----------------|
| Ultra Fast | 1s | Every poll | HIGH |
| Fast | 10s | Every poll | MEDIUM |
| Slow | 60s | Every poll | LOW |

**Impact**:
- Ultra fast loop (1s) acquires lock every second
- Fast loop (10s) also acquires lock, potentially blocking ultra fast
- Slow loop (60s) can block both fast loops
- Lock acquisition overhead: ~0.1-1ms per acquisition

**Evidence**:
```python
# hub.py:114 - Single lock for all reads
self._read_lock = asyncio.Lock()

# hub.py:336 - Ultra fast uses same lock
result = await modbus_readers.read_additional_modbus_data_1_part_2(client, self._read_lock)

# hub.py:256 - Slow poll also uses same lock
res = await method(client, self._read_lock)
```

### 2.2 Connection Check Overhead (MEDIUM IMPACT)

**Problem**: `get_client()` called every second with lock acquisition

**Impact**:
- `_connection_lock` acquired every 1s
- `client.connected` property check
- Potential reconnection logic triggered

**Evidence**:
```python
# services.py:55-59
async def get_client(self) -> ModbusTcpClient:
    async with self._connection_lock:  # Lock every 1s
        self._client = await connect_if_needed(self._client, self._host, self._port)
        return self._client
```

### 2.3 Full Register Read Without Selectivity (HIGH IMPACT)

**Problem**: Reads all 25 registers every second, even if values unchanged

**Impact**:
- Network I/O: 25 registers Ã— 2 bytes = 50 bytes per poll
- Decoding overhead: 18 values decoded every second
- No change detection before read

**Evidence**:
```python
# modbus_readers.py:292-296
"additional_data_1_part_2": {
    "address": 16533,
    "count": 25,  # All 25 registers read every 1s
    "decode_map": ADDITIONAL_DATA_1_PART_2_MAP,  # 18 values decoded
}
```

### 2.4 MQTT Publishing Overhead (MEDIUM IMPACT)

**Problem**: Publishes all fast data every second without batching

**Impact**:
- 18 MQTT messages per second (if all values change)
- Circuit breaker overhead on each publish
- No throttling or deduplication

**Evidence**:
```python
# hub.py:342
await self.mqtt.publish_data(fast_data)  # Every 1s

# services.py:344-347
messages = []
for key, value in data.items():
    safe_key = key.split("/")[-1] if "/" in key else key
    messages.append((safe_key, str(value)))  # Individual messages
```

### 2.5 Dictionary Update Overhead (LOW IMPACT)

**Problem**: Full dictionary update every second without change detection

**Impact**:
- `self.inverter_data.update(result)` copies all values
- No comparison with previous values
- Unnecessary memory writes

**Evidence**:
```python
# hub.py:341
self.inverter_data.update(result)  # Full update every 1s
```

### 2.6 No Caching Mechanism (HIGH IMPACT)

**Problem**: No caching of decoded values or register reads

**Impact**:
- Same values decoded every second
- No memoization
- No TTL-based cache invalidation

### 2.7 Redundant Data Processing (MEDIUM IMPACT)

**Problem**: Same data processed every second regardless of changes

**Impact**:
- Dictionary comprehension for filtering
- No early exit if values unchanged
- No delta updates

---

## 3. Optimization Strategies

### 3.1 Selective Register Fetching (HIGH IMPACT)

**Strategy**: Only read registers for sensors that actually changed

**Implementation**:

```python
# Add to hub.py
class SAJModbusHub(DataUpdateCoordinator[Dict[str, Any]]):
    def __init__(self, hass: HomeAssistant, config_entry: ConfigEntry) -> None:
        # ... existing code ...
        
        # Add change tracking
        self._last_register_values: Dict[int, int] = {}
        self._register_change_threshold: float = 0.01  # 1% change threshold
        self._consecutive_unchanged_reads: int = 0
        self._adaptive_poll_interval: float = 1.0

async def _async_update_fast(self, now=None, ultra: bool = False) -> None:
    """Perform fast update with selective fetching."""
    if not self.fast_enabled and not ultra:
        return
    
    try:
        client = await self.connection.get_client()
        
        # Check if we should skip this read based on adaptive interval
        if ultra and self._consecutive_unchanged_reads > 10:
            # Reduce polling frequency when values are stable
            self._adaptive_poll_interval = min(5.0, self._adaptive_poll_interval * 1.1)
            return
        
        result = await modbus_readers.read_additional_modbus_data_1_part_2(
            client, self._read_lock
        )
        
        if result:
            # Detect changes
            changes = self._detect_changes(result)
            
            if not changes:
                self._consecutive_unchanged_reads += 1
                return  # Skip update if no changes
            
            self._consecutive_unchanged_reads = 0
            self._adaptive_poll_interval = 1.0  # Reset to fast polling
            
            fast_data = {k: v for k, v in result.items() if k in self._fast_poll_sensor_keys}
            if fast_data:
                self.inverter_data.update(result)
                await self.mqtt.publish_data(fast_data)
                
                if not ultra:
                    for listener in self._fast_listeners:
                        listener()
    except ReconnectionNeededError:
        await self.connection.reconnect()
    except Exception as e:
        _LOGGER.warning("Fast update failed: %s", e)

def _detect_changes(self, new_data: Dict[str, Any]) -> bool:
    """Detect if any values changed significantly."""
    for key, new_value in new_data.items():
        if key in self._fast_poll_sensor_keys:
            old_value = self.inverter_data.get(key)
            if old_value is None:
                return True  # First read
            
            # Calculate percentage change
            if old_value != 0:
                change_pct = abs((new_value - old_value) / old_value)
                if change_pct > self._register_change_threshold:
                    return True
            elif new_value != 0:
                return True
    
    return False
```

**Estimated Impact**: 30-50% reduction in unnecessary updates when values are stable

---

### 3.2 Lock Optimization (HIGH IMPACT)

**Strategy**: Use separate locks for different polling intervals

**Implementation**:

```python
# hub.py - Modify lock initialization
class SAJModbusHub(DataUpdateCoordinator[Dict[str, Any]]):
    def __init__(self, hass: HomeAssistant, config_entry: ConfigEntry) -> None:
        # ... existing code ...
        
        # Separate locks for different polling intervals
        self._ultra_fast_read_lock = asyncio.Lock()  # For 1s polling
        self._fast_read_lock = asyncio.Lock()  # For 10s polling
        self._slow_read_lock = asyncio.Lock()  # For 60s polling
        
        # Keep _read_lock for backward compatibility
        self._read_lock = self._slow_read_lock

# hub.py - Modify ultra fast update
async def _async_update_fast(self, now=None, ultra: bool = False) -> None:
    """Perform fast update with dedicated lock."""
    if not self.fast_enabled and not ultra:
        return
    
    try:
        client = await self.connection.get_client()
        
        # Use dedicated lock for ultra fast mode
        lock = self._ultra_fast_read_lock if ultra else self._fast_read_lock
        result = await modbus_readers.read_additional_modbus_data_1_part_2(client, lock)
        
        # ... rest of the code ...
```

**Alternative: Read-Write Lock Pattern**

```python
# Add to hub.py
from asyncio import Lock, Event

class ReadWriteLock:
    """Simple read-write lock implementation."""
    
    def __init__(self):
        self._readers = 0
        self._writer = False
        self._read_ready = Event()
        self._read_ready.set()
        self._write_ready = Event()
        self._write_ready.set()
        self._lock = Lock()
    
    async def acquire_read(self):
        """Acquire read lock."""
        async with self._lock:
            self._readers += 1
            if self._readers == 1:
                await self._write_ready.wait()
    
    async def release_read(self):
        """Release read lock."""
        async with self._lock:
            self._readers -= 1
            if self._readers == 0:
                self._read_ready.set()
    
    async def acquire_write(self):
        """Acquire write lock."""
        await self._read_ready.wait()
        async with self._lock:
            self._writer = True
            self._read_ready.clear()
    
    async def release_write(self):
        """Release write lock."""
        async with self._lock:
            self._writer = False
            self._write_ready.set()
```

**Estimated Impact**: 20-40% reduction in lock contention

---

### 3.3 Connection Pooling and Health Monitoring (MEDIUM IMPACT)

**Strategy**: Keep connection open and reduce connection check frequency

**Implementation**:

```python
# services.py - Add connection health monitoring
class ModbusConnectionManager:
    def __init__(self, hass: HomeAssistant, host: str, port: int):
        # ... existing code ...
        
        # Add health monitoring
        self._last_health_check = 0.0
        self._health_check_interval = 30.0  # Check every 30s
        self._connection_healthy = True
        self._cached_client = None
        self._cache_expiry = 0.0
        self._cache_ttl = 60.0  # Cache client for 60s
    
    async def get_client(self) -> ModbusTcpClient:
        """Returns a connected client with caching."""
        now = time.monotonic()
        
        # Return cached client if still valid
        if (self._cached_client is not None and 
            self._cached_client.connected and 
            now < self._cache_expiry):
            return self._cached_client
        
        # Need to refresh connection
        async with self._connection_lock:
            # Double-check after acquiring lock
            if (self._cached_client is not None and 
                self._cached_client.connected and 
                now < self._cache_expiry):
                return self._cached_client
            
            self._cached_client = await connect_if_needed(
                self._cached_client, self._host, self._port
            )
            self._cache_expiry = now + self._cache_ttl
            return self._cached_client
    
    async def check_connection_health(self) -> bool:
        """Check connection health without full reconnect."""
        now = time.monotonic()
        
        if now - self._last_health_check < self._health_check_interval:
            return self._connection_healthy
        
        self._last_health_check = now
        
        if self._cached_client and self._cached_client.connected:
            self._connection_healthy = True
            return True
        
        self._connection_healthy = False
        return False
```

**Estimated Impact**: 10-20% reduction in connection overhead

---

### 3.4 Batch MQTT Publishing (MEDIUM IMPACT)

**Strategy**: Accumulate changes and publish in batches

**Implementation**:

```python
# services.py - Add batch publishing
class MqttPublisher:
    def __init__(self, hass: HomeAssistant, host: str, port: int, user: str, 
                 password: str, topic_prefix: str, publish_all: bool, 
                 ultra_fast_enabled: bool, use_ha_mqtt: bool = False):
        # ... existing code ...
        
        # Add batch publishing
        self._pending_messages: Dict[str, str] = {}
        self._batch_size = 10
        self._batch_timeout = 2.0  # Publish after 2s even if batch not full
        self._last_publish_time = 0.0
        self._batch_task: Optional[asyncio.Task] = None
    
    async def publish_data(self, data: Dict[str, Any], force: bool = False) -> None:
        """Publish data with batching."""
        if not data or self.strategy == self.STRATEGY_NONE:
            return
        
        # Add to pending messages
        for key, value in data.items():
            safe_key = key.split("/")[-1] if "/" in key else key
            self._pending_messages[safe_key] = str(value)
        
        now = time.monotonic()
        
        # Check if we should publish now
        should_publish = (
            force or
            len(self._pending_messages) >= self._batch_size or
            (now - self._last_publish_time) >= self._batch_timeout
        )
        
        if should_publish:
            await self._flush_pending_messages()
    
    async def _flush_pending_messages(self) -> None:
        """Flush all pending messages to MQTT."""
        if not self._pending_messages:
            return
        
        messages = list(self._pending_messages.items())
        self._pending_messages.clear()
        self._last_publish_time = time.monotonic()
        
        # Publish all messages
        if self.strategy == self.STRATEGY_HA:
            try:
                is_connected = mqtt.is_connected(self.hass)
                if is_connected:
                    for key, payload in messages:
                        topic = f"{self.topic_prefix}/{key}"
                        await self._circuit_breaker.call(
                            mqtt.async_publish, self.hass, topic, payload
                        )
            except Exception as e:
                _LOGGER.debug("HA MQTT publish failed: %s", e)
        
        elif self.strategy == self.STRATEGY_PAHO and self._paho_client:
            try:
                if not self._paho_started:
                    self._paho_client.connect_async(self.host, self.port)
                    self._paho_client.loop_start()
                    self._paho_started = True
                
                if self._paho_client.is_connected():
                    for key, payload in messages:
                        self._paho_client.publish(f"{self.topic_prefix}/{key}", payload)
            except Exception as e:
                _LOGGER.warning("Internal MQTT publish failed: %s", e)
```

**Estimated Impact**: 15-25% reduction in MQTT overhead

---

### 3.5 Data Caching with TTL (HIGH IMPACT)

**Strategy**: Cache decoded values with TTL-based invalidation

**Implementation**:

```python
# hub.py - Add caching
from datetime import datetime, timedelta
from typing import Dict, Any, Optional

class CachedValue:
    """Cached value with TTL."""
    
    def __init__(self, value: Any, ttl: float = 5.0):
        self.value = value
        self.expiry = datetime.now() + timedelta(seconds=ttl)
    
    def is_valid(self) -> bool:
        """Check if cached value is still valid."""
        return datetime.now() < self.expiry
    
    def get(self) -> Optional[Any]:
        """Get value if valid, None otherwise."""
        return self.value if self.is_valid() else None

class SAJModbusHub(DataUpdateCoordinator[Dict[str, Any]]):
    def __init__(self, hass: HomeAssistant, config_entry: ConfigEntry) -> None:
        # ... existing code ...
        
        # Add caching
        self._value_cache: Dict[str, CachedValue] = {}
        self._cache_ttl = 5.0  # Cache values for 5 seconds
    
    def _get_cached_value(self, key: str) -> Optional[Any]:
        """Get cached value if valid."""
        cached = self._value_cache.get(key)
        if cached and cached.is_valid():
            return cached.get()
        return None
    
    def _set_cached_value(self, key: str, value: Any) -> None:
        """Set cached value with TTL."""
        self._value_cache[key] = CachedValue(value, self._cache_ttl)
    
    async def _async_update_fast(self, now=None, ultra: bool = False) -> None:
        """Perform fast update with caching."""
        if not self.fast_enabled and not ultra:
            return
        
        try:
            client = await self.connection.get_client()
            result = await modbus_readers.read_additional_modbus_data_1_part_2(
                client, self._read_lock
            )
            
            if result:
                # Filter out unchanged values using cache
                filtered_result = {}
                for key, value in result.items():
                    if key in self._fast_poll_sensor_keys:
                        cached = self._get_cached_value(key)
                        if cached is None or cached != value:
                            filtered_result[key] = value
                            self._set_cached_value(key, value)
                
                if filtered_result:
                    self.inverter_data.update(filtered_result)
                    await self.mqtt.publish_data(filtered_result)
                    
                    if not ultra:
                        for listener in self._fast_listeners:
                            listener()
        except ReconnectionNeededError:
            await self.connection.reconnect()
        except Exception as e:
            _LOGGER.warning("Fast update failed: %s", e)
```

**Estimated Impact**: 40-60% reduction in unnecessary updates

---

### 3.6 Lazy Loading of Decoded Values (MEDIUM IMPACT)

**Strategy**: Only decode values when needed

**Implementation**:

```python
# modbus_readers.py - Add lazy decoding
from typing import Callable, Awaitable

class LazyDecodedValue:
    """Lazy decoded value that only decodes when accessed."""
    
    def __init__(self, raw_value: int, decoder: Callable[[int], Any]):
        self._raw_value = raw_value
        self._decoder = decoder
        self._decoded: Optional[Any] = None
        self._decoded_flag = False
    
    def get(self) -> Any:
        """Get decoded value, decoding on first access."""
        if not self._decoded_flag:
            self._decoded = self._decoder(self._raw_value)
            self._decoded_flag = True
        return self._decoded
    
    def __eq__(self, other: Any) -> bool:
        """Compare decoded values."""
        return self.get() == other

async def _read_modbus_data_lazy(
    client: ModbusTcpClient,
    lock: Lock,
    start_address: int,
    count: int,
    decode_instructions: List[tuple],
    data_key: str,
    default_decoder: str = "16u",
    default_factor: float = 0.01,
) -> Dict[str, LazyDecodedValue]:
    """Helper function to read Modbus data with lazy decoding."""
    try:
        regs = await try_read_registers(client, lock, 1, start_address, count)
        
        if not regs:
            _LOGGER.error("Error reading modbus data: No response for %s", data_key)
            return {}
        
        new_data = {}
        index = 0
        
        for instruction in decode_instructions:
            key, method, factor = (instruction + (default_factor,))[:3]
            method = method or default_decoder
            
            if method == "skip_bytes":
                index += factor // 2
                continue
            if not key or index >= len(regs):
                continue
            
            try:
                raw_value = regs[index]
                
                # Create lazy decoder
                def make_decoder(method: str, factor: float, raw: int):
                    def decoder(r: int) -> Any:
                        if method == "16i":
                            value = client.convert_from_registers([r], ModbusClientMixin.DATATYPE.INT16)
                        elif method == "16u":
                            value = client.convert_from_registers([r], ModbusClientMixin.DATATYPE.UINT16)
                        elif method == "32u":
                            value = client.convert_from_registers([r], ModbusClientMixin.DATATYPE.UINT32)
                        else:
                            value = r
                        return round(value * factor, 2) if factor != 1 else value
                    return decoder
                
                new_data[key] = LazyDecodedValue(raw_value, make_decoder(method, factor, raw_value))
            except Exception as e:
                _LOGGER.error("Error decoding %s: %s", key, e)
            finally:
                index += 1
        
        return new_data
    
    except Exception as e:
        _LOGGER.error("Error reading modbus data: %s", e)
        return {}
```

**Estimated Impact**: 10-15% reduction in CPU usage

---

### 3.7 Delta Updates for MQTT (LOW IMPACT)

**Strategy**: Only publish changed values to MQTT

**Implementation**:

```python
# hub.py - Add delta tracking
class SAJModbusHub(DataUpdateCoordinator[Dict[str, Any]]):
    def __init__(self, hass: HomeAssistant, config_entry: ConfigEntry) -> None:
        # ... existing code ...
        
        # Add delta tracking
        self._last_published_values: Dict[str, Any] = {}
    
    async def _async_update_fast(self, now=None, ultra: bool = False) -> None:
        """Perform fast update with delta MQTT publishing."""
        if not self.fast_enabled and not ultra:
            return
        
        try:
            client = await self.connection.get_client()
            result = await modbus_readers.read_additional_modbus_data_1_part_2(
                client, self._read_lock
            )
            
            if result:
                fast_data = {k: v for k, v in result.items() if k in self._fast_poll_sensor_keys}
                
                # Calculate delta
                delta_data = {}
                for key, value in fast_data.items():
                    last_value = self._last_published_values.get(key)
                    if last_value != value:
                        delta_data[key] = value
                        self._last_published_values[key] = value
                
                if delta_data:
                    self.inverter_data.update(result)
                    await self.mqtt.publish_data(delta_data)  # Only publish changes
                    
                    if not ultra:
                        for listener in self._fast_listeners:
                            listener()
        except ReconnectionNeededError:
            await self.connection.reconnect()
        except Exception as e:
            _LOGGER.warning("Fast update failed: %s", e)
```

**Estimated Impact**: 20-30% reduction in MQTT messages

---

## 4. Performance Impact Summary

| Optimization | Impact Level | Estimated Improvement | Complexity |
|--------------|--------------|----------------------|------------|
| Selective Register Fetching | HIGH | 30-50% reduction in updates | MEDIUM |
| Lock Optimization | HIGH | 20-40% reduction in contention | LOW |
| Data Caching with TTL | HIGH | 40-60% reduction in updates | LOW |
| Connection Pooling | MEDIUM | 10-20% reduction in overhead | MEDIUM |
| Batch MQTT Publishing | MEDIUM | 15-25% reduction in overhead | MEDIUM |
| Lazy Loading | MEDIUM | 10-15% reduction in CPU | HIGH |
| Delta Updates | LOW | 20-30% reduction in messages | LOW |

**Combined Estimated Impact**: 60-80% reduction in resource usage

---

## 5. Implementation Priority

### Phase 1: Quick Wins (Low Complexity, High Impact)
1. **Lock Optimization** - Separate locks for different intervals
2. **Data Caching with TTL** - Simple cache implementation
3. **Delta Updates for MQTT** - Only publish changed values

### Phase 2: Medium Effort (Medium Complexity, Medium Impact)
4. **Connection Pooling** - Reduce connection check frequency
5. **Batch MQTT Publishing** - Accumulate and batch messages

### Phase 3: Advanced (High Complexity, High Impact)
6. **Selective Register Fetching** - Adaptive polling based on changes
7. **Lazy Loading** - Decode values on demand

---

## 6. Additional Considerations

### 6.1 Memory Usage
- Caching increases memory usage
- Implement cache size limits
- Use LRU eviction for large caches

### 6.2 Data Freshness
- Caching may reduce data freshness
- Balance between performance and freshness
- Allow configuration of cache TTL

### 6.3 Error Handling
- Maintain robust error handling
- Don't sacrifice reliability for performance
- Implement fallback mechanisms

### 6.4 Configuration
- Make optimizations configurable
- Allow users to disable specific optimizations
- Provide sensible defaults

---

## 7. Testing Recommendations

1. **Benchmark current performance** before implementing changes
2. **Test each optimization independently** to measure impact
3. **Monitor resource usage** (CPU, memory, network)
4. **Verify data accuracy** after optimizations
5. **Test under load** with multiple polling intervals active
6. **Measure MQTT message rate** before and after

---

## 8. Conclusion

The ultra fast mode implementation has several optimization opportunities that can significantly reduce resource usage while maintaining data freshness. The most impactful optimizations are:

1. **Selective Register Fetching** - Only read when values change
2. **Lock Optimization** - Separate locks for different intervals
3. **Data Caching** - Cache decoded values with TTL

Implementing these optimizations in phases allows for incremental improvements with measurable impact at each stage.
